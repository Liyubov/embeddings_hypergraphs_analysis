{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WaqebRhA-o8",
        "outputId": "0975ac7c-da8e-45db-c1e8-df541bd50409"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.4.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.19.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YkPMpIBrBFSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "from torch_geometric.data import Data, Dataset\n",
        "\n",
        "# Generate synthetic graphs\n",
        "def generate_graphs(num_samples=100):\n",
        "    graphs = []\n",
        "    labels = []\n",
        "\n",
        "    # Class 1: Erdős-Rényi (random)\n",
        "    for _ in range(num_samples):\n",
        "        G = nx.erdos_renyi_graph(n=20, p=0.15)\n",
        "        graphs.append(G)\n",
        "        labels.append(0)  # Label 0 for ER\n",
        "\n",
        "    # Class 2: Barabási-Albert (scale-free)\n",
        "    for _ in range(num_samples):\n",
        "        G = nx.barabasi_albert_graph(n=20, m=3)\n",
        "        graphs.append(G)\n",
        "        labels.append(1)  # Label 1 for BA\n",
        "\n",
        "    # Class 3: Ordered grid\n",
        "    for _ in range(num_samples):\n",
        "        G = nx.grid_2d_graph(5, 4)  # 5x4 grid\n",
        "        graphs.append(G)\n",
        "        labels.append(2)  # Label 2 for Grid\n",
        "\n",
        "    return graphs, labels\n",
        "\n",
        "graphs, labels = generate_graphs()"
      ],
      "metadata": {
        "id": "tyAUTtLiBFnU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert graphs to PyTorch Geometric Format\n",
        "\n",
        "Add graph features and convert to PyG Data object\n",
        "\n",
        "https://pytorch-geometric.readthedocs.io/en/latest/"
      ],
      "metadata": {
        "id": "DuBZxHglBeUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.utils import from_networkx\n",
        "import torch\n",
        "\n",
        "def preprocess_graph(G, label):\n",
        "    # Convert to PyG Data\n",
        "    data = from_networkx(G)\n",
        "\n",
        "    # Add node features (degree + clustering coefficient)\n",
        "    data.x = torch.tensor([[G.degree(node), nx.clustering(G, node)] for node in G.nodes()], dtype=torch.float)\n",
        "\n",
        "    # Add graph label\n",
        "    data.y = torch.tensor([label], dtype=torch.long)\n",
        "\n",
        "    return data\n",
        "\n",
        "dataset = [preprocess_graph(G, label) for G, label in zip(graphs, labels)]"
      ],
      "metadata": {
        "id": "zlj_bdtcBZha"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define GNN Classifier\n",
        "\n",
        "Use a 2-layer or 3-layer GCN with global pooling.\n",
        "\n",
        "GNN architecture can be various."
      ],
      "metadata": {
        "id": "Z8GDbYPICJcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "\n",
        "class GraphClassifier(torch.nn.Module):\n",
        "    def __init__(self, hidden_dim=64, num_classes=3):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(2, hidden_dim)  # Input: 2 features (degree, clustering)\n",
        "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
        "        self.fc = torch.nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = global_mean_pool(x, batch)  # Graph-level embedding\n",
        "        return F.log_softmax(self.fc(x), dim=1)"
      ],
      "metadata": {
        "id": "gXERHhlfCGTn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the Model\n",
        "\n",
        "Split data and train the model."
      ],
      "metadata": {
        "id": "t7g7c5yPCt9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# accuracy plotting\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Split dataset\n",
        "train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42) # for interpetability\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=32)\n",
        "\n",
        "# Initialize model and optimizer\n",
        "model = GraphClassifier()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = torch.nn.NLLLoss()\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(100):\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        out = model(batch)\n",
        "        loss = criterion(out, batch.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Validate\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for batch in test_loader:\n",
        "        pred = model(batch).argmax(dim=1)\n",
        "        correct += (pred == batch.y).sum().item()\n",
        "    print(f'Epoch {epoch}, Accuracy: {correct / len(test_loader.dataset):.2f}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, len(val_accuracies)+1), val_accuracies, label='Validation Accuracy', marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Validation Accuracy per Epoch')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLdVI5ZFCpn7",
        "outputId": "2a469aed-044d-4882-dbae-52ed11d6f793"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Accuracy: 0.37\n",
            "Epoch 1, Accuracy: 0.27\n",
            "Epoch 2, Accuracy: 0.65\n",
            "Epoch 3, Accuracy: 0.78\n",
            "Epoch 4, Accuracy: 0.77\n",
            "Epoch 5, Accuracy: 0.87\n",
            "Epoch 6, Accuracy: 0.87\n",
            "Epoch 7, Accuracy: 0.98\n",
            "Epoch 8, Accuracy: 0.95\n",
            "Epoch 9, Accuracy: 0.97\n",
            "Epoch 10, Accuracy: 0.93\n",
            "Epoch 11, Accuracy: 1.00\n",
            "Epoch 12, Accuracy: 1.00\n",
            "Epoch 13, Accuracy: 1.00\n",
            "Epoch 14, Accuracy: 0.93\n",
            "Epoch 15, Accuracy: 0.95\n",
            "Epoch 16, Accuracy: 1.00\n",
            "Epoch 17, Accuracy: 1.00\n",
            "Epoch 18, Accuracy: 1.00\n",
            "Epoch 19, Accuracy: 1.00\n",
            "Epoch 20, Accuracy: 1.00\n",
            "Epoch 21, Accuracy: 1.00\n",
            "Epoch 22, Accuracy: 1.00\n",
            "Epoch 23, Accuracy: 1.00\n",
            "Epoch 24, Accuracy: 1.00\n",
            "Epoch 25, Accuracy: 1.00\n",
            "Epoch 26, Accuracy: 1.00\n",
            "Epoch 27, Accuracy: 1.00\n",
            "Epoch 28, Accuracy: 1.00\n",
            "Epoch 29, Accuracy: 1.00\n",
            "Epoch 30, Accuracy: 1.00\n",
            "Epoch 31, Accuracy: 1.00\n",
            "Epoch 32, Accuracy: 1.00\n",
            "Epoch 33, Accuracy: 1.00\n",
            "Epoch 34, Accuracy: 1.00\n",
            "Epoch 35, Accuracy: 1.00\n",
            "Epoch 36, Accuracy: 1.00\n",
            "Epoch 37, Accuracy: 1.00\n",
            "Epoch 38, Accuracy: 1.00\n",
            "Epoch 39, Accuracy: 1.00\n",
            "Epoch 40, Accuracy: 1.00\n",
            "Epoch 41, Accuracy: 1.00\n",
            "Epoch 42, Accuracy: 1.00\n",
            "Epoch 43, Accuracy: 1.00\n",
            "Epoch 44, Accuracy: 1.00\n",
            "Epoch 45, Accuracy: 1.00\n",
            "Epoch 46, Accuracy: 1.00\n",
            "Epoch 47, Accuracy: 1.00\n",
            "Epoch 48, Accuracy: 1.00\n",
            "Epoch 49, Accuracy: 1.00\n",
            "Epoch 50, Accuracy: 1.00\n",
            "Epoch 51, Accuracy: 1.00\n",
            "Epoch 52, Accuracy: 1.00\n",
            "Epoch 53, Accuracy: 1.00\n",
            "Epoch 54, Accuracy: 1.00\n",
            "Epoch 55, Accuracy: 1.00\n",
            "Epoch 56, Accuracy: 1.00\n",
            "Epoch 57, Accuracy: 1.00\n",
            "Epoch 58, Accuracy: 1.00\n",
            "Epoch 59, Accuracy: 1.00\n",
            "Epoch 60, Accuracy: 1.00\n",
            "Epoch 61, Accuracy: 1.00\n",
            "Epoch 62, Accuracy: 1.00\n",
            "Epoch 63, Accuracy: 1.00\n",
            "Epoch 64, Accuracy: 1.00\n",
            "Epoch 65, Accuracy: 1.00\n",
            "Epoch 66, Accuracy: 1.00\n",
            "Epoch 67, Accuracy: 1.00\n",
            "Epoch 68, Accuracy: 1.00\n",
            "Epoch 69, Accuracy: 1.00\n",
            "Epoch 70, Accuracy: 1.00\n",
            "Epoch 71, Accuracy: 1.00\n",
            "Epoch 72, Accuracy: 1.00\n",
            "Epoch 73, Accuracy: 1.00\n",
            "Epoch 74, Accuracy: 1.00\n",
            "Epoch 75, Accuracy: 1.00\n",
            "Epoch 76, Accuracy: 1.00\n",
            "Epoch 77, Accuracy: 1.00\n",
            "Epoch 78, Accuracy: 1.00\n",
            "Epoch 79, Accuracy: 1.00\n",
            "Epoch 80, Accuracy: 1.00\n",
            "Epoch 81, Accuracy: 1.00\n",
            "Epoch 82, Accuracy: 1.00\n",
            "Epoch 83, Accuracy: 1.00\n",
            "Epoch 84, Accuracy: 1.00\n",
            "Epoch 85, Accuracy: 1.00\n",
            "Epoch 86, Accuracy: 1.00\n",
            "Epoch 87, Accuracy: 1.00\n",
            "Epoch 88, Accuracy: 1.00\n",
            "Epoch 89, Accuracy: 1.00\n",
            "Epoch 90, Accuracy: 1.00\n",
            "Epoch 91, Accuracy: 1.00\n",
            "Epoch 92, Accuracy: 1.00\n",
            "Epoch 93, Accuracy: 1.00\n",
            "Epoch 94, Accuracy: 1.00\n",
            "Epoch 95, Accuracy: 1.00\n",
            "Epoch 96, Accuracy: 1.00\n",
            "Epoch 97, Accuracy: 1.00\n",
            "Epoch 98, Accuracy: 1.00\n",
            "Epoch 99, Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see the accuracy levels which we plot for each epoch to characterise when GNN actually 'learned' the graph structure.\n",
        "\n"
      ],
      "metadata": {
        "id": "RuUb2WOFEcBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "# accuracy plotting\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Lists to track metrics\n",
        "train_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(100):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        out = model(batch)\n",
        "        loss = criterion(out, batch.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    train_losses.append(epoch_loss / len(train_loader))\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for batch in test_loader:\n",
        "        pred = model(batch).argmax(dim=1)\n",
        "        correct += (pred == batch.y).sum().item()\n",
        "    accuracy = correct / len(test_loader.dataset)\n",
        "    val_accuracies.append(accuracy)\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Loss: {train_losses[-1]:.4f}, Acc: {val_accuracies[-1]:.4f}')\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, len(val_accuracies)+1), val_accuracies, label='Validation Accuracy', marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Validation Accuracy per Epoch')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Training Loss', color='red')\n",
        "plt.twinx()\n",
        "plt.plot(val_accuracies, label='Validation Accuracy', color='blue')\n",
        "plt.title('Training Loss & Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "EfPm9rYMEu3Z",
        "outputId": "4daf7af0-1cc2-4acf-b177-a35c204ce615"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# accuracy plotting \\n\\nimport matplotlib.pyplot as plt\\n\\n# Lists to track metrics\\ntrain_losses = []\\nval_accuracies = []\\n\\n# Training loop\\nfor epoch in range(100):\\n    model.train()\\n    epoch_loss = 0\\n    for batch in train_loader:\\n        optimizer.zero_grad()\\n        out = model(batch)\\n        loss = criterion(out, batch.y)\\n        loss.backward()\\n        optimizer.step()\\n        epoch_loss += loss.item()\\n    train_losses.append(epoch_loss / len(train_loader))\\n    \\n    # Validation\\n    model.eval()\\n    correct = 0\\n    for batch in test_loader:\\n        pred = model(batch).argmax(dim=1)\\n        correct += (pred == batch.y).sum().item()\\n    accuracy = correct / len(test_loader.dataset)\\n    val_accuracies.append(accuracy)\\n    \\n    print(f'Epoch {epoch+1}, Loss: {train_losses[-1]:.4f}, Acc: {val_accuracies[-1]:.4f}')\\n\\n# Plotting\\nplt.figure(figsize=(10, 5))\\nplt.plot(range(1, len(val_accuracies)+1), val_accuracies, label='Validation Accuracy', marker='o')\\nplt.xlabel('Epoch')\\nplt.ylabel('Accuracy')\\nplt.title('Validation Accuracy per Epoch')\\nplt.legend()\\nplt.grid(True)\\nplt.show()\\n\\nplt.figure(figsize=(10, 5))\\nplt.plot(train_losses, label='Training Loss', color='red')\\nplt.twinx()\\nplt.plot(val_accuracies, label='Validation Accuracy', color='blue')\\nplt.title('Training Loss & Validation Accuracy')\\nplt.legend()\\nplt.show()\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WjvCJfEMEuHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_graph(model, G):\n",
        "    # Preprocess (ensure same features as training)\n",
        "    data = preprocess_graph(G, label=-1)  # Dummy label\n",
        "    data.batch = torch.zeros(data.num_nodes, dtype=torch.long)  # Single graph\n",
        "\n",
        "    # Predict\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out = model(data)\n",
        "        pred = out.argmax().item()\n",
        "\n",
        "    return ['Erdős-Rényi', 'Barabási-Albert', 'Grid'][pred]\n",
        "\n",
        "# Example usage\n",
        "#new_graph = nx.barabasi_albert_graph(n=20, m=3)  # Should predict BA\n",
        "\n",
        "new_graph = nx.erdos_renyi_graph(n=20, p=0.1\n",
        "                                )  # Should predict BA\n",
        "\n",
        "# only predicts it when it is for lower p=0.1 not for p > 0.5\n",
        "\n",
        "print(classify_graph(model, new_graph))  # Output: \"Barabási-Albert\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwtghVPVEshY",
        "outputId": "05a41ddb-50c3-4cc0-ecfe-a2d9aca2a148"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Erdős-Rényi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F2khPw34DZbQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}